{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50956755",
   "metadata": {
    "papermill": {
     "duration": 0.004129,
     "end_time": "2025-05-27T03:06:57.406406",
     "exception": false,
     "start_time": "2025-05-27T03:06:57.402277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installing Scikit-learn GPUs acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9952fa4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:06:57.414273Z",
     "iopub.status.busy": "2025-05-27T03:06:57.413964Z",
     "iopub.status.idle": "2025-05-27T03:07:43.708292Z",
     "shell.execute_reply": "2025-05-27T03:07:43.707489Z"
    },
    "papermill": {
     "duration": 46.304769,
     "end_time": "2025-05-27T03:07:43.714848",
     "exception": false,
     "start_time": "2025-05-27T03:06:57.410079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-27 03:07:09.931] [CUML] [info] cuML: Installed accelerator for sklearn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 03:07:24.435627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748315244.633373      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748315244.693322      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-27 03:07:43.618] [CUML] [info] cuML: Installed accelerator for umap.\n",
      "[2025-05-27 03:07:43.705] [CUML] [info] cuML: Installed accelerator for hdbscan.\n",
      "[2025-05-27 03:07:43.705] [CUML] [info] cuML: Successfully initialized accelerator.\n"
     ]
    }
   ],
   "source": [
    "%load_ext cuml.accel\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a543b6a1",
   "metadata": {
    "papermill": {
     "duration": 0.005939,
     "end_time": "2025-05-27T03:07:43.726853",
     "exception": false,
     "start_time": "2025-05-27T03:07:43.720914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Use this command to run python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155a6dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:07:43.739722Z",
     "iopub.status.busy": "2025-05-27T03:07:43.739223Z",
     "iopub.status.idle": "2025-05-27T03:07:44.718471Z",
     "shell.execute_reply": "2025-05-27T03:07:44.717875Z"
    },
    "papermill": {
     "duration": 0.987013,
     "end_time": "2025-05-27T03:07:44.719745",
     "exception": false,
     "start_time": "2025-05-27T03:07:43.732732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import io\n",
    "import contextlib\n",
    "import optuna\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafcc300",
   "metadata": {
    "papermill": {
     "duration": 0.003163,
     "end_time": "2025-05-27T03:07:44.726646",
     "exception": false,
     "start_time": "2025-05-27T03:07:44.723483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00aef341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:07:44.734460Z",
     "iopub.status.busy": "2025-05-27T03:07:44.733819Z",
     "iopub.status.idle": "2025-05-27T03:07:44.744742Z",
     "shell.execute_reply": "2025-05-27T03:07:44.744239Z"
    },
    "papermill": {
     "duration": 0.015851,
     "end_time": "2025-05-27T03:07:44.745715",
     "exception": false,
     "start_time": "2025-05-27T03:07:44.729864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    fnames = os.listdir(path)\n",
    "    datalist = [pd.read_csv(os.path.join(path, fname)) for fname in tqdm(fnames)]\n",
    "    dataframe = pd.concat(datalist)\n",
    "    for d in datalist: del d\n",
    "    dataframe.columns = dataframe.columns.str.strip()\n",
    "    return dataframe\n",
    "\n",
    "def clean_data(dataframe):\n",
    "    dataframe.columns = dataframe.columns.str.strip()\n",
    "    dataframe.drop_duplicates(inplace=True)\n",
    "    \n",
    "    numeric_cols = dataframe.select_dtypes(include=np.number).columns\n",
    "    dataframe.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    dataframe.drop(columns=[\"Fwd Header Length.1\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    # Fill missing values\n",
    "    if 'Flow Bytes/s' in dataframe.columns:\n",
    "        med_flow_bytes = dataframe['Flow Bytes/s'].median()\n",
    "        dataframe['Flow Bytes/s'] = dataframe['Flow Bytes/s'].fillna(med_flow_bytes)\n",
    "    \n",
    "    if 'Flow Packets/s' in dataframe.columns:\n",
    "        med_flow_packets = dataframe['Flow Packets/s'].median()\n",
    "        dataframe['Flow Packets/s'] = dataframe['Flow Packets/s'].fillna(med_flow_packets)\n",
    "\n",
    "    dataframe['Attack Type'] = dataframe['Label'].apply(lambda x: 'BENIGN' if str(x).lower() == 'benign' or str(x) == '0' else 'ATTACK')\n",
    "    dataframe.drop('Label', axis=1, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def preprocess_data(dataframe, is_train=True, scaler=None, ipca=None, kept_columns=None):\n",
    "    # Optimize dtypes\n",
    "    for col in dataframe.columns:\n",
    "        col_type = dataframe[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min = dataframe[col].min()\n",
    "            c_max = dataframe[col].max()\n",
    "            if str(col_type).find('float') >= 0 and c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                dataframe[col] = dataframe[col].astype(np.float32)\n",
    "            elif str(col_type).find('int') >= 0 and c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                dataframe[col] = dataframe[col].astype(np.int32)\n",
    "\n",
    "    if is_train:\n",
    "        # Drop constant columns\n",
    "        num_unique = dataframe.nunique()\n",
    "        kept_columns = num_unique[num_unique > 1].index\n",
    "        dataframe = dataframe[kept_columns]\n",
    "    else:\n",
    "        dataframe = dataframe[kept_columns]\n",
    "\n",
    "    # Separate features and label\n",
    "    attacks = dataframe['Attack Type']\n",
    "    features = dataframe.drop('Attack Type', axis=1)\n",
    "\n",
    "    if is_train:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "        n_components = len(features.columns) // 2\n",
    "        ipca = IncrementalPCA(n_components=n_components, batch_size=500)\n",
    "        for batch in np.array_split(scaled_features, len(features) // 500 + 1):\n",
    "            ipca.partial_fit(batch)\n",
    "    else:\n",
    "        scaled_features = scaler.transform(features)\n",
    "\n",
    "    transformed_features = ipca.transform(scaled_features)\n",
    "    data = pd.DataFrame(transformed_features, columns=[f'PC{i+1}' for i in range(transformed_features.shape[1])])\n",
    "    \n",
    "    # Add labels after feature columns\n",
    "    data['Attack Number'] = attacks.apply(lambda x: 1 if x == 'ATTACK' else 0).values\n",
    "\n",
    "    # Optional: shuffle rows\n",
    "    data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    if is_train:\n",
    "        return data, scaler, ipca, kept_columns\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f7ff2cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:07:44.753237Z",
     "iopub.status.busy": "2025-05-27T03:07:44.752722Z",
     "iopub.status.idle": "2025-05-27T03:07:44.763274Z",
     "shell.execute_reply": "2025-05-27T03:07:44.762759Z"
    },
    "papermill": {
     "duration": 0.015356,
     "end_time": "2025-05-27T03:07:44.764324",
     "exception": false,
     "start_time": "2025-05-27T03:07:44.748968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelFineTuner:\n",
    "    def __init__(self, model_name, n_trials=50):\n",
    "        self.model_name = model_name\n",
    "        self.n_trials = n_trials\n",
    "        self.study = optuna.create_study(direction='maximize')\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "\n",
    "    def _rf_objective(self, trial, X_train, y_train, X_test, y_test):\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 100, 400)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 5, 50)\n",
    "    \n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_scores = model.predict_proba(X_test)[:, 1]\n",
    "        return average_precision_score(y_test, y_scores)\n",
    "\n",
    "    def _xgb_objective(self, trial, X_train, y_train, X_test, y_test):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 40),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.5, 5),\n",
    "            \"use_label_encoder\": False,\n",
    "            \"eval_metric\": \"logloss\"\n",
    "        }\n",
    "    \n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_scores = model.predict_proba(X_test)[:, 1]\n",
    "        return average_precision_score(y_test, y_scores)\n",
    "\n",
    "    def _lgbm_objective(self, trial, X_train, y_train, X_test, y_test):\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 30),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            \"class_weight\": 'balanced',\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_scores = model.predict_proba(X_test)[:, 1]\n",
    "        return average_precision_score(y_test, y_scores)\n",
    "\n",
    "    def fine_tune(self, X_train, y_train, X_test, y_test):\n",
    "        objective_mapping = {\n",
    "            'RandomForest': self._rf_objective,\n",
    "            'XGBoost': self._xgb_objective,\n",
    "            'LightGBM': self._lgbm_objective\n",
    "        }\n",
    "    \n",
    "        if self.model_name not in objective_mapping:\n",
    "            raise ValueError(f\"Unsupported model name: {self.model_name}\")\n",
    "    \n",
    "        print(f\"=== Tuning {self.model_name} ===\")\n",
    "        self.study.optimize(lambda trial: objective_mapping[self.model_name](trial, X_train, y_train, X_test, y_test), \n",
    "                            n_trials=self.n_trials)\n",
    "    \n",
    "        best_params = self.study.best_params\n",
    "        self.best_params = best_params\n",
    "    \n",
    "        if self.model_name == 'RandomForest':\n",
    "            self.best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "        elif self.model_name == 'XGBoost':\n",
    "            self.best_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "        elif self.model_name == 'LightGBM':\n",
    "            self.best_model = LGBMClassifier(**best_params)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {self.model_name}\")\n",
    "    \n",
    "        self.best_model.fit(X_train, y_train)\n",
    "        preds = self.best_model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        report = classification_report(y_test, preds, output_dict=True)\n",
    "    \n",
    "        return self.best_model, acc, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d4736e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:07:44.771925Z",
     "iopub.status.busy": "2025-05-27T03:07:44.771717Z",
     "iopub.status.idle": "2025-05-27T03:07:44.791262Z",
     "shell.execute_reply": "2025-05-27T03:07:44.790581Z"
    },
    "papermill": {
     "duration": 0.024872,
     "end_time": "2025-05-27T03:07:44.792455",
     "exception": false,
     "start_time": "2025-05-27T03:07:44.767583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OptunaMABThompsonSampling:\n",
    "    def __init__(self, n_clusters, n_trials=3):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_trials = n_trials\n",
    "        self.model_names = ['RandomForest', 'XGBoost', 'LightGBM']\n",
    "        self.n_arms = len(self.model_names)\n",
    "        self.arms = [None] * self.n_arms\n",
    "        self.alpha = np.ones((n_clusters, self.n_arms))\n",
    "        self.beta = np.ones((n_clusters, self.n_arms))\n",
    "        self.cluster_models = [None] * n_clusters\n",
    "        self.max_merges_per_cluster = 4\n",
    "        self.cluster_merge_count = {i: 0 for i in range(n_clusters)}\n",
    "        self.history = [[] for _ in range(self.n_clusters)]\n",
    "        self.cluster_mapping = {}  # Track cluster merging\n",
    "\n",
    "    def select_arm(self, cluster_id):\n",
    "        samples = np.random.beta(self.alpha[cluster_id], self.beta[cluster_id])\n",
    "        return np.argmax(samples)\n",
    "\n",
    "    def update(self, cluster_id, arm_id, reward):\n",
    "        self.alpha[cluster_id, arm_id] += reward\n",
    "        self.beta[cluster_id, arm_id] += 1 - reward\n",
    "\n",
    "    def _merge_clusters(self, source_cluster, target_cluster, X_train, y_train):\n",
    "        print(f\"[Cluster {source_cluster}] merging into [Cluster {target_cluster}]\")\n",
    "    \n",
    "        source_mask = self.cluster_assignments == source_cluster\n",
    "        self.cluster_assignments[source_mask] = target_cluster\n",
    "    \n",
    "        self.cluster_mapping[source_cluster] = target_cluster\n",
    "        self.cluster_merge_count[target_cluster] += 1\n",
    "    \n",
    "        # Recompute center\n",
    "        target_mask = self.cluster_assignments == target_cluster\n",
    "        self.cluster_centers[target_cluster] = np.mean(X_train[target_mask], axis=0)\n",
    "\n",
    "    def train_and_evaluate(self, X_train, y_train, X_val, y_val):\n",
    "        # Initial clustering\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "        self.cluster_assignments = self.kmeans.fit_predict(X_train)\n",
    "        self.cluster_centers = self.kmeans.cluster_centers_.copy()\n",
    "        \n",
    "        # Initialize cluster mapping\n",
    "        self.cluster_mapping = {i: i for i in range(self.n_clusters)}\n",
    "        \n",
    "        # Handle clusters with insufficient class diversity\n",
    "        for cluster_id in range(self.n_clusters):\n",
    "            cluster_mask = self.cluster_assignments == cluster_id\n",
    "            cluster_y_train = y_train[cluster_mask]\n",
    "        \n",
    "            if len(cluster_y_train) == 0:\n",
    "                continue\n",
    "        \n",
    "            if len(np.unique(cluster_y_train)) < 2:\n",
    "                # Tìm cluster gần nhất về mặt khoảng cách + có đủ nhãn + chưa bị merge quá nhiều\n",
    "                dists = np.linalg.norm(self.cluster_centers - self.cluster_centers[cluster_id], axis=1)\n",
    "                nearest_ids = np.argsort(dists)\n",
    "        \n",
    "                merged = False\n",
    "                for target_id in nearest_ids:\n",
    "                    if target_id == cluster_id:\n",
    "                        continue\n",
    "        \n",
    "                    if self.cluster_merge_count[target_id] >= self.max_merges_per_cluster:\n",
    "                        continue\n",
    "        \n",
    "                    target_mask = self.cluster_assignments == target_id\n",
    "                    target_y = y_train[target_mask]\n",
    "        \n",
    "                    if len(target_y) > 0 and len(np.unique(target_y)) >= 2:\n",
    "                        self._merge_clusters(cluster_id, target_id, X_train, y_train)\n",
    "                        merged = True\n",
    "                        break\n",
    "        \n",
    "                if not merged:\n",
    "                    print(f\"[Warning] Could not merge cluster {cluster_id} - no suitable target found\")\n",
    "\n",
    "        # Get validation cluster assignments using updated mapping\n",
    "        raw_val_clusters = self.kmeans.predict(X_val)\n",
    "        val_cluster_assignments = np.array([self.cluster_mapping.get(c, c) for c in raw_val_clusters])\n",
    "        \n",
    "        total_preds = []\n",
    "        total_labels = []\n",
    "        \n",
    "        # Train models for each effective cluster\n",
    "        active_clusters = set(self.cluster_assignments)\n",
    "        \n",
    "        for cluster_id in active_clusters:\n",
    "            cluster_mask = self.cluster_assignments == cluster_id\n",
    "            cluster_X_train = X_train[cluster_mask]\n",
    "            cluster_y_train = y_train[cluster_mask]\n",
    "            \n",
    "            val_mask = val_cluster_assignments == cluster_id\n",
    "            cluster_X_val = X_val[val_mask]\n",
    "            cluster_y_val = y_val[val_mask]\n",
    "            \n",
    "            if len(cluster_X_train) == 0:\n",
    "                print(f\"[Cluster {cluster_id}] has no training data after merging.\")\n",
    "                continue\n",
    "                \n",
    "            if len(cluster_X_val) == 0:\n",
    "                print(f\"[Cluster {cluster_id}] has no validation data.\")\n",
    "                # Still train the model for this cluster\n",
    "                pass\n",
    "            \n",
    "            print(f\"\\n[Cluster {cluster_id}] Training data: {len(cluster_X_train)}, \"\n",
    "                  f\"Validation data: {len(cluster_X_val)}, \"\n",
    "                  f\"Classes: {np.unique(cluster_y_train)}\")\n",
    "            \n",
    "            best_arm_id = -1\n",
    "            best_reward = -1\n",
    "            best_model = None\n",
    "            \n",
    "            print(f\"[Cluster {cluster_id}] Training all arms...\")\n",
    "            for arm_id, model_name in enumerate(self.model_names):\n",
    "                try:\n",
    "                    tuner = ModelFineTuner(model_name, n_trials=self.n_trials)\n",
    "                    if len(cluster_X_val) > 0:\n",
    "                        model, acc, report = tuner.fine_tune(cluster_X_train, cluster_y_train, \n",
    "                                                           cluster_X_val, cluster_y_val)\n",
    "                    else:\n",
    "                        # Use cross-validation if no validation data\n",
    "                        from sklearn.model_selection import cross_val_score\n",
    "                        model, _, _ = tuner.fine_tune(cluster_X_train, cluster_y_train, \n",
    "                                                    cluster_X_train[:1], cluster_y_train[:1])  # dummy validation\n",
    "                        acc = np.mean(cross_val_score(model, cluster_X_train, cluster_y_train, cv=3))\n",
    "                    \n",
    "                    print(f\"[Cluster {cluster_id}] Arm {arm_id} ({model_name}) Accuracy: {acc:.4f}\")\n",
    "                    \n",
    "                    if acc > best_reward:\n",
    "                        best_reward = acc\n",
    "                        best_arm_id = arm_id\n",
    "                        best_model = model\n",
    "                    \n",
    "                    self.history[cluster_id].append((arm_id, acc))\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"[Cluster {cluster_id}] Arm {arm_id} ({model_name}) failed: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if best_model is not None:\n",
    "                # Update Thompson Sampling\n",
    "                self.update(cluster_id, best_arm_id, best_reward)\n",
    "                self.cluster_models[cluster_id] = best_model\n",
    "                self.arms[best_arm_id] = best_model\n",
    "                \n",
    "                # Make predictions on validation data if available\n",
    "                if len(cluster_X_val) > 0:\n",
    "                    preds = best_model.predict(cluster_X_val)\n",
    "                    total_preds.extend(preds)\n",
    "                    total_labels.extend(cluster_y_val)\n",
    "                \n",
    "                print(f\"[Cluster {cluster_id}] Selected Arm: {best_arm_id} \"\n",
    "                      f\"({self.model_names[best_arm_id]}) with Accuracy: {best_reward:.4f}\")\n",
    "            else:\n",
    "                print(f\"[Cluster {cluster_id}] No successful model training\")\n",
    "        \n",
    "        if len(total_preds) > 0:\n",
    "            print(\"\\n=== Overall Evaluation ===\")\n",
    "            print(\"Accuracy:\", accuracy_score(total_labels, total_preds))\n",
    "            print(classification_report(total_labels, total_preds))\n",
    "        else:\n",
    "            print(\"\\n=== No validation predictions available ===\")\n",
    "\n",
    "    def lenapollon_predict(self, X_test, y_test):\n",
    "        \"\"\"Fixed prediction method that respects cluster merging\"\"\"\n",
    "        # Get raw cluster assignments\n",
    "        raw_test_clusters = self.kmeans.predict(X_test)\n",
    "        \n",
    "        # Apply cluster mapping to get effective cluster assignments\n",
    "        test_cluster_assignments = np.array([self.cluster_mapping.get(c, c) for c in raw_test_clusters])\n",
    "        \n",
    "        y_pred = np.zeros(len(X_test))\n",
    "        \n",
    "        for cluster_id in range(self.n_clusters):\n",
    "            cluster_mask = test_cluster_assignments == cluster_id\n",
    "            cluster_X_test = X_test[cluster_mask]\n",
    "            \n",
    "            if len(cluster_X_test) == 0:\n",
    "                continue\n",
    "\n",
    "            print(f\"Predicting cluster {cluster_id} with {len(cluster_X_test)} samples\")\n",
    "            \n",
    "            model = self.cluster_models[cluster_id]\n",
    "            if model is not None:\n",
    "                try:\n",
    "                    y_pred[cluster_mask] = model.predict(cluster_X_test)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Prediction failed for cluster {cluster_id}: {str(e)}\")\n",
    "            else:\n",
    "                print(f\"[Warning] No trained model for cluster {cluster_id}. \"\n",
    "                      f\"Using fallback prediction.\")\n",
    "                # Fallback: use the most successful arm globally\n",
    "                fallback_arm = np.argmax([len([h for hist in self.history for h in hist if h[0] == i]) \n",
    "                                        for i in range(self.n_arms)])\n",
    "                if self.arms[fallback_arm] is not None:\n",
    "                    y_pred[cluster_mask] = self.arms[fallback_arm].predict(cluster_X_test)\n",
    "        \n",
    "        print(\"\\n=== Testing Performance ===\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Additional diagnostics\n",
    "        print(f\"\\nCluster distribution in test set:\")\n",
    "        unique_clusters, counts = np.unique(test_cluster_assignments, return_counts=True)\n",
    "        for cluster_id, count in zip(unique_clusters, counts):\n",
    "            print(f\"Cluster {cluster_id}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "500fcdf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:07:44.799570Z",
     "iopub.status.busy": "2025-05-27T03:07:44.799380Z",
     "iopub.status.idle": "2025-05-27T03:09:03.788370Z",
     "shell.execute_reply": "2025-05-27T03:09:03.787733Z"
    },
    "papermill": {
     "duration": 78.993955,
     "end_time": "2025-05-27T03:09:03.789700",
     "exception": false,
     "start_time": "2025-05-27T03:07:44.795745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:24<00:00,  3.07s/it]\n"
     ]
    }
   ],
   "source": [
    "train_df = get_data(path='/kaggle/input/network-intrusion-dataset')\n",
    "cleaned_train_df = clean_data(train_df)\n",
    "preprocessed_train_df, scaler, ipca, kept_columns = preprocess_data(cleaned_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0927afa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:09:03.798555Z",
     "iopub.status.busy": "2025-05-27T03:09:03.798326Z",
     "iopub.status.idle": "2025-05-27T03:09:03.913425Z",
     "shell.execute_reply": "2025-05-27T03:09:03.912847Z"
    },
    "papermill": {
     "duration": 0.120493,
     "end_time": "2025-05-27T03:09:03.914428",
     "exception": false,
     "start_time": "2025-05-27T03:09:03.793935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack Type\n",
       "BENIGN    2096484\n",
       "ATTACK     425878\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df['Attack Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb4ca87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:09:03.922661Z",
     "iopub.status.busy": "2025-05-27T03:09:03.922476Z",
     "iopub.status.idle": "2025-05-27T03:09:03.941360Z",
     "shell.execute_reply": "2025-05-27T03:09:03.940669Z"
    },
    "papermill": {
     "duration": 0.024154,
     "end_time": "2025-05-27T03:09:03.942381",
     "exception": false,
     "start_time": "2025-05-27T03:09:03.918227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack Number\n",
       "0    2096484\n",
       "1     425878\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_df['Attack Number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f0c6b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:09:03.950964Z",
     "iopub.status.busy": "2025-05-27T03:09:03.950762Z",
     "iopub.status.idle": "2025-05-27T03:09:03.956955Z",
     "shell.execute_reply": "2025-05-27T03:09:03.956440Z"
    },
    "papermill": {
     "duration": 0.011765,
     "end_time": "2025-05-27T03:09:03.957970",
     "exception": false,
     "start_time": "2025-05-27T03:09:03.946205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standardize_data(test_df):\n",
    "    test_df.drop(columns=['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Protocol', 'Timestamp'], errors=\"ignore\", inplace=True)\n",
    "    column_mapping = {\n",
    "        'Dst Port': 'Destination Port',\n",
    "        'Tot Fwd Pkts': 'Total Fwd Packets',\n",
    "        'Tot Bwd Pkts': 'Total Backward Packets',\n",
    "        'TotLen Fwd Pkts': 'Total Length of Fwd Packets',\n",
    "        'TotLen Bwd Pkts': 'Total Length of Bwd Packets',\n",
    "        'Fwd Pkt Len Max': 'Fwd Packet Length Max',\n",
    "        'Fwd Pkt Len Min': 'Fwd Packet Length Min',\n",
    "        'Fwd Pkt Len Mean': 'Fwd Packet Length Mean',\n",
    "        'Fwd Pkt Len Std': 'Fwd Packet Length Std',\n",
    "        'Bwd Pkt Len Max': 'Bwd Packet Length Max',\n",
    "        'Bwd Pkt Len Min': 'Bwd Packet Length Min',\n",
    "        'Bwd Pkt Len Mean': 'Bwd Packet Length Mean',\n",
    "        'Bwd Pkt Len Std': 'Bwd Packet Length Std',\n",
    "        'Flow Byts/s': 'Flow Bytes/s',\n",
    "        'Flow Pkts/s': 'Flow Packets/s',\n",
    "        'Fwd IAT Tot': 'Fwd IAT Total',\n",
    "        'Bwd IAT Tot': 'Bwd IAT Total',\n",
    "        'Fwd IAT Mean': 'Fwd IAT Mean',\n",
    "        'Fwd IAT Std': 'Fwd IAT Std',\n",
    "        'Fwd IAT Max': 'Fwd IAT Max',\n",
    "        'Fwd IAT Min': 'Fwd IAT Min',\n",
    "        'Bwd IAT Mean': 'Bwd IAT Mean',\n",
    "        'Bwd IAT Std': 'Bwd IAT Std',\n",
    "        'Bwd IAT Max': 'Bwd IAT Max',\n",
    "        'Bwd IAT Min': 'Bwd IAT Min',\n",
    "        'Fwd PSH Flags': 'Fwd PSH Flags',\n",
    "        'Bwd PSH Flags': 'Bwd PSH Flags',\n",
    "        'Fwd URG Flags': 'Fwd URG Flags',\n",
    "        'Bwd URG Flags': 'Bwd URG Flags',\n",
    "        'Fwd Header Len': 'Fwd Header Length',\n",
    "        'Bwd Header Len': 'Bwd Header Length',\n",
    "        'Fwd Pkts/s': 'Fwd Packets/s',\n",
    "        'Bwd Pkts/s': 'Bwd Packets/s',\n",
    "        'Pkt Len Min': 'Min Packet Length',\n",
    "        'Pkt Len Max': 'Max Packet Length',\n",
    "        'Pkt Len Mean': 'Packet Length Mean',\n",
    "        'Pkt Len Std': 'Packet Length Std',\n",
    "        'Pkt Len Var': 'Packet Length Variance',\n",
    "        'FIN Flag Cnt': 'FIN Flag Count',\n",
    "        'SYN Flag Cnt': 'SYN Flag Count',\n",
    "        'RST Flag Cnt': 'RST Flag Count',\n",
    "        'PSH Flag Cnt': 'PSH Flag Count',\n",
    "        'ACK Flag Cnt': 'ACK Flag Count',\n",
    "        'URG Flag Cnt': 'URG Flag Count',\n",
    "        'CWE Flag Count': 'CWE Flag Count',\n",
    "        'ECE Flag Cnt': 'ECE Flag Count',\n",
    "        'Pkt Size Avg': 'Average Packet Size',\n",
    "        'Fwd Seg Size Avg': 'Avg Fwd Segment Size',\n",
    "        'Bwd Seg Size Avg': 'Avg Bwd Segment Size',\n",
    "        'Fwd Byts/b Avg': 'Fwd Avg Bytes/Bulk',\n",
    "        'Fwd Pkts/b Avg': 'Fwd Avg Packets/Bulk',\n",
    "        'Fwd Blk Rate Avg': 'Fwd Avg Bulk Rate',\n",
    "        'Bwd Byts/b Avg': 'Bwd Avg Bytes/Bulk',\n",
    "        'Bwd Pkts/b Avg': 'Bwd Avg Packets/Bulk',\n",
    "        'Bwd Blk Rate Avg': 'Bwd Avg Bulk Rate',\n",
    "        'Subflow Fwd Pkts': 'Subflow Fwd Packets',\n",
    "        'Subflow Fwd Byts': 'Subflow Fwd Bytes',\n",
    "        'Subflow Bwd Pkts': 'Subflow Bwd Packets',\n",
    "        'Subflow Bwd Byts': 'Subflow Bwd Bytes',\n",
    "        'Init Fwd Win Byts': 'Init_Win_bytes_forward',\n",
    "        'Init Bwd Win Byts': 'Init_Win_bytes_backward',\n",
    "        'Fwd Act Data Pkts': 'act_data_pkt_fwd',\n",
    "        'Fwd Seg Size Min': 'min_seg_size_forward',\n",
    "        'Fwd Header Len': 'Fwd Header Length',\n",
    "    }\n",
    "    test_df = test_df.rename(columns=column_mapping)\n",
    "    test_cleaned_df = clean_data(test_df)\n",
    "    return test_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5035563",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:09:03.966915Z",
     "iopub.status.busy": "2025-05-27T03:09:03.966718Z",
     "iopub.status.idle": "2025-05-27T03:09:03.971568Z",
     "shell.execute_reply": "2025-05-27T03:09:03.970882Z"
    },
    "papermill": {
     "duration": 0.010825,
     "end_time": "2025-05-27T03:09:03.972657",
     "exception": false,
     "start_time": "2025-05-27T03:09:03.961832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def balance_labels(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Trả về X và y đã được cân bằng giữa các nhãn bằng cách undersample.\n",
    "    \"\"\"\n",
    "    # Tách nhãn\n",
    "    mask_0 = y == 0\n",
    "    mask_1 = y == 1\n",
    "\n",
    "    count_0 = mask_0.sum()\n",
    "    count_1 = mask_1.sum()\n",
    "    min_count = min(count_0, count_1)\n",
    "\n",
    "    # Undersample cho cả hai lớp\n",
    "    X_bal = pd.concat([\n",
    "        X[mask_0].sample(n=min_count, random_state=random_state),\n",
    "        X[mask_1].sample(n=min_count, random_state=random_state)\n",
    "    ])\n",
    "    y_bal = pd.concat([\n",
    "        y[mask_0].sample(n=min_count, random_state=random_state),\n",
    "        y[mask_1].sample(n=min_count, random_state=random_state)\n",
    "    ])\n",
    "\n",
    "    # Shuffle\n",
    "    X_bal = X_bal.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    y_bal = y_bal.reset_index(drop=True)\n",
    "\n",
    "    return X_bal, y_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c8462",
   "metadata": {
    "papermill": {
     "duration": 0.003547,
     "end_time": "2025-05-27T03:09:03.979939",
     "exception": false,
     "start_time": "2025-05-27T03:09:03.976392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GAN of duckduck (using PCAP file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c18f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:09:03.988003Z",
     "iopub.status.busy": "2025-05-27T03:09:03.987777Z",
     "iopub.status.idle": "2025-05-27T03:09:04.706646Z",
     "shell.execute_reply": "2025-05-27T03:09:04.705827Z"
    },
    "papermill": {
     "duration": 0.72445,
     "end_time": "2025-05-27T03:09:04.708078",
     "exception": false,
     "start_time": "2025-05-27T03:09:03.983628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "benign_df = pd.read_csv(\"/kaggle/input/duckduck-gan/benign_adv.csv\")\n",
    "benign_df['Label'] = 'Benign'\n",
    "attack_df = pd.read_csv(\"/kaggle/input/duckduck-gan/apacheddos_adv.csv\")\n",
    "ddos_ip = ['172.28.30.88', '172.28.31.235', '172.28.30.90']\n",
    "attack_df['Label'] = attack_df.apply(lambda x: 'Attack' if x['Dst IP'] == '172.28.31.229' and x['Src IP'] in ddos_ip else 'Benign', axis=1)\n",
    "test_df = pd.concat([benign_df, attack_df], ignore_index=True)\n",
    "standardized_test_df = standardize_data(test_df)\n",
    "preprocessed_test_df = preprocess_data(standardized_test_df, False, scaler, ipca, kept_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a1594",
   "metadata": {
    "papermill": {
     "duration": 0.003791,
     "end_time": "2025-05-27T03:09:04.716230",
     "exception": false,
     "start_time": "2025-05-27T03:09:04.712439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Demo Apache DDoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8e61a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:09:04.724566Z",
     "iopub.status.busy": "2025-05-27T03:09:04.724339Z",
     "iopub.status.idle": "2025-05-27T03:09:04.727656Z",
     "shell.execute_reply": "2025-05-27T03:09:04.726953Z"
    },
    "papermill": {
     "duration": 0.008743,
     "end_time": "2025-05-27T03:09:04.728694",
     "exception": false,
     "start_time": "2025-05-27T03:09:04.719951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# benign_df = pd.read_csv(\"/kaggle/input/ml4sec-project-demo/benign_traffic.csv\")\n",
    "# benign_df['Label'] = 'Benign'\n",
    "# attack_df = pd.read_csv(\"/kaggle/input/ml4sec-project-demo/apache_ddos.csv\")\n",
    "# ddos_ip = ['172.28.30.88', '172.28.31.235', '172.28.30.90']\n",
    "# attack_df['Label'] = attack_df.apply(lambda x: 'Attack' if x['Dst IP'] == '172.28.31.229' and x['Src IP'] in ddos_ip else 'Benign', axis=1)\n",
    "# test_df = pd.concat([benign_df, attack_df], ignore_index=True)\n",
    "# standardized_test_df = standardize_data(test_df)\n",
    "# preprocessed_test_df = preprocess_data(standardized_test_df, False, scaler, ipca, kept_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6b226",
   "metadata": {
    "papermill": {
     "duration": 0.003796,
     "end_time": "2025-05-27T03:09:04.736339",
     "exception": false,
     "start_time": "2025-05-27T03:09:04.732543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GAN of baobao (using CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7f27906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:09:04.745140Z",
     "iopub.status.busy": "2025-05-27T03:09:04.744541Z",
     "iopub.status.idle": "2025-05-27T03:09:04.747689Z",
     "shell.execute_reply": "2025-05-27T03:09:04.747026Z"
    },
    "papermill": {
     "duration": 0.008549,
     "end_time": "2025-05-27T03:09:04.748810",
     "exception": false,
     "start_time": "2025-05-27T03:09:04.740261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv(\"/kaggle/input/baobao-ganadv/adv_cicids2017.csv\")\n",
    "# test_df = test_df.drop(test_df.columns[0], axis=1)\n",
    "# cleaned_test_df = clean_data(test_df)\n",
    "# preprocessed_test_df = preprocess_data(cleaned_test_df, False, scaler, ipca, kept_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85ee711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:09:04.757391Z",
     "iopub.status.busy": "2025-05-27T03:09:04.756844Z",
     "iopub.status.idle": "2025-05-27T03:22:47.850743Z",
     "shell.execute_reply": "2025-05-27T03:22:47.849921Z"
    },
    "papermill": {
     "duration": 823.099558,
     "end_time": "2025-05-27T03:22:47.852186",
     "exception": false,
     "start_time": "2025-05-27T03:09:04.752628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cluster 1] merging into [Cluster 0]\n",
      "[Cluster 2] merging into [Cluster 0]\n",
      "[Cluster 3] merging into [Cluster 0]\n",
      "[Cluster 4] merging into [Cluster 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 03:09:13,666] A new study created in memory with name: no-name-aa67d8a4-fdf4-48ae-8aa1-8eb83782f48d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Cluster 0] Training data: 1765653, Validation data: 756709, Classes: [0 1]\n",
      "[Cluster 0] Training all arms...\n",
      "=== Tuning RandomForest ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 03:10:12,374] Trial 0 finished with value: 0.9996811272641396 and parameters: {'n_estimators': 194, 'max_depth': 24}. Best is trial 0 with value: 0.9996811272641396.\n",
      "[I 2025-05-27 03:10:38,162] Trial 1 finished with value: 0.9937404299367041 and parameters: {'n_estimators': 150, 'max_depth': 8}. Best is trial 0 with value: 0.9996811272641396.\n",
      "[I 2025-05-27 03:12:19,833] Trial 2 finished with value: 0.999581152129107 and parameters: {'n_estimators': 339, 'max_depth': 41}. Best is trial 0 with value: 0.9996811272641396.\n",
      "[I 2025-05-27 03:13:19,915] A new study created in memory with name: no-name-5c512dd7-cd01-4828-b6ad-50fb0023c698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cluster 0] Arm 0 (RandomForest) Accuracy: 0.9980\n",
      "=== Tuning XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 03:14:39,097] Trial 0 finished with value: 0.9997679905791479 and parameters: {'n_estimators': 270, 'max_depth': 37, 'learning_rate': 0.07846656934268532, 'scale_pos_weight': 2.252702559609424}. Best is trial 0 with value: 0.9997679905791479.\n",
      "[I 2025-05-27 03:15:13,364] Trial 1 finished with value: 0.9997646435062961 and parameters: {'n_estimators': 99, 'max_depth': 36, 'learning_rate': 0.19884439201216852, 'scale_pos_weight': 4.277785800287642}. Best is trial 0 with value: 0.9997679905791479.\n",
      "[I 2025-05-27 03:15:27,045] Trial 2 finished with value: 0.9990897688101951 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.1830138391213584, 'scale_pos_weight': 4.435285527148478}. Best is trial 0 with value: 0.9997679905791479.\n",
      "[I 2025-05-27 03:16:48,198] A new study created in memory with name: no-name-f5ee7fa1-6704-42d8-a942-13bbb20809c2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cluster 0] Arm 1 (XGBoost) Accuracy: 0.9982\n",
      "=== Tuning LightGBM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 03:18:14,958] Trial 0 finished with value: 0.9991138339355614 and parameters: {'max_depth': 11, 'num_leaves': 29, 'learning_rate': 0.019090414940533523, 'feature_fraction': 0.7055586276558419, 'bagging_fraction': 0.8067345834114653, 'bagging_freq': 3, 'min_child_samples': 40, 'n_estimators': 461}. Best is trial 0 with value: 0.9991138339355614.\n",
      "[I 2025-05-27 03:20:09,215] Trial 1 finished with value: 0.9996796322149771 and parameters: {'max_depth': 12, 'num_leaves': 85, 'learning_rate': 0.022282262840819397, 'feature_fraction': 0.7986692042750179, 'bagging_fraction': 0.6022735116528658, 'bagging_freq': 2, 'min_child_samples': 29, 'n_estimators': 491}. Best is trial 1 with value: 0.9996796322149771.\n",
      "[I 2025-05-27 03:20:39,670] Trial 2 finished with value: 0.9993171650621409 and parameters: {'max_depth': 30, 'num_leaves': 93, 'learning_rate': 0.03519357215580011, 'feature_fraction': 0.7485317706788674, 'bagging_fraction': 0.9267613025444202, 'bagging_freq': 2, 'min_child_samples': 42, 'n_estimators': 107}. Best is trial 1 with value: 0.9996796322149771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cluster 0] Arm 2 (LightGBM) Accuracy: 0.9980\n",
      "[Cluster 0] Selected Arm: 1 (XGBoost) with Accuracy: 0.9982\n",
      "\n",
      "=== Overall Evaluation ===\n",
      "Accuracy: 0.9981697059239417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    628946\n",
      "           1       0.99      1.00      0.99    127763\n",
      "\n",
      "    accuracy                           1.00    756709\n",
      "   macro avg       1.00      1.00      1.00    756709\n",
      "weighted avg       1.00      1.00      1.00    756709\n",
      "\n",
      "Predicting cluster 0 with 24945 samples\n",
      "\n",
      "=== Testing Performance ===\n",
      "Accuracy: 0.24401683704149127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.37      5458\n",
      "           1       0.96      0.03      0.07     19487\n",
      "\n",
      "    accuracy                           0.24     24945\n",
      "   macro avg       0.59      0.51      0.22     24945\n",
      "weighted avg       0.80      0.24      0.13     24945\n",
      "\n",
      "\n",
      "Cluster distribution in test set:\n",
      "Cluster 0: 24945 samples\n"
     ]
    }
   ],
   "source": [
    "X = preprocessed_train_df.copy().drop('Attack Number', axis=1)\n",
    "y = preprocessed_train_df['Attack Number']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "mab = OptunaMABThompsonSampling(n_clusters=5)\n",
    "mab.train_and_evaluate(X_train.values, y_train.values, X_val.values, y_val.values)\n",
    "X_test = preprocessed_test_df.copy().drop('Attack Number', axis=1)\n",
    "y_test = preprocessed_test_df['Attack Number']\n",
    "mab.lenapollon_predict(X_test.values, y_test.values)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 902298,
     "sourceId": 1530359,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3674161,
     "sourceId": 6376134,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7499669,
     "sourceId": 11929088,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7502583,
     "sourceId": 11933438,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7500181,
     "sourceId": 11939892,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 957.7164,
   "end_time": "2025-05-27T03:22:50.939643",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-27T03:06:53.223243",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
